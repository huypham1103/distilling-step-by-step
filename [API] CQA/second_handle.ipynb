{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'contrastive.csv'\n",
    "df = pd.read_csv(path, index_col=0)[['premise', 'hypothesis', 'prompt', 'rationale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hypothesis'] = df['hypothesis'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rationale = df.rationale.astype(str)\n",
    "df['split'] = df.rationale.apply(lambda x: x.lower().split('most likely answer'))\n",
    "df.split = df.split.apply(lambda x : x[1] if len(x) > 1 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"There are 10 apples on an apple tree.  Three ...</td>\n",
       "      <td>[park, coloring book, garden center, math prob...</td>\n",
       "      <td>Questions: \"There are 10 apples on an apple tr...</td>\n",
       "      <td>1. The most likely answer is **(D) math proble...</td>\n",
       "      <td>is **(d) math problem**. this is an example o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  \"There are 10 apples on an apple tree.  Three ...   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  [park, coloring book, garden center, math prob...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Questions: \"There are 10 apples on an apple tr...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  1. The most likely answer is **(D) math proble...   \n",
       "\n",
       "                                               split  \n",
       "0   is **(d) math problem**. this is an example o...  "
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct index\n",
    "df['correct_index'] = [{} for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    for choice in row['hypothesis']:\n",
    "        if choice in row['split']:\n",
    "            row['correct_index'][choice] = row['split'].lower().index(choice.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM_answer'] = df.correct_index.apply(lambda x: min(x, key=x.get) if len(x) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read paper's answer\n",
    "paper = pd.read_csv('paper.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['premise'] = paper.input.str.split('\\n').apply(lambda x: x[0])\n",
    "paper.set_index('premise', inplace=True)\n",
    "paper.index = paper.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('premise', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['my_label'] = df['LLM_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229134585771481"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(paper.label == paper.my_label) / len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('contrastive - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?</th>\n",
       "      <td>[park, coloring book, garden center, math prob...</td>\n",
       "      <td>Questions: \"There are 10 apples on an apple tr...</td>\n",
       "      <td>1. The correct answer is (D) math problem. Thi...</td>\n",
       "      <td>1. the correct answer is (d) math problem. thi...</td>\n",
       "      <td>{'math problem': 29}</td>\n",
       "      <td>math problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A John is a bum.  Much like the stereotype, he lives near this sort of transportation infrastructure. Where does he live?</th>\n",
       "      <td>[bus depot, beach, train station, bridge, bridge]</td>\n",
       "      <td>Questions: A John is a bum.  Much like the ste...</td>\n",
       "      <td>2. The correct answer is (D) bridge. A John is...</td>\n",
       "      <td>2. the correct answer is (d) bridge. a john is...</td>\n",
       "      <td>{'bridge': 29}</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A bad person places little value on being honest, acting without pretense or being what?</th>\n",
       "      <td>[excellent, upright, premium, competent, sincere]</td>\n",
       "      <td>Questions: A bad person places little value on...</td>\n",
       "      <td>3. The correct answer is (E) sincere. A bad pe...</td>\n",
       "      <td>3. the correct answer is (e) sincere. a bad pe...</td>\n",
       "      <td>{'sincere': 29}</td>\n",
       "      <td>sincere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A bald eagle flies over St. Paul, where is it?</th>\n",
       "      <td>[texas, thermal, minnesota, canada, photograph]</td>\n",
       "      <td>Questions: A bald eagle flies over St. Paul, w...</td>\n",
       "      <td>4. The correct answer is (C) minnesota. A bald...</td>\n",
       "      <td>4. the correct answer is (c) minnesota. a bald...</td>\n",
       "      <td>{'minnesota': 29}</td>\n",
       "      <td>minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A battleship is a powerful vessel.  If you need something similar but faster, what would you use?</th>\n",
       "      <td>[yatch, corvette, aircraft carrier, destroyer,...</td>\n",
       "      <td>Questions: A battleship is a powerful vessel. ...</td>\n",
       "      <td>5. The correct answer is (D) destroyer. A batt...</td>\n",
       "      <td>5. the correct answer is (d) destroyer. a batt...</td>\n",
       "      <td>{'destroyer': 29}</td>\n",
       "      <td>destroyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where is a pleasure garden likely to have orginated?</th>\n",
       "      <td>[fairy tale, resort town, english courtyard, p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2. The correct answer is (D) palace. A pleasur...</td>\n",
       "      <td>2. the correct answer is (d) palace. a pleasur...</td>\n",
       "      <td>{'fairy tale': 229, 'resort town': 243, 'engli...</td>\n",
       "      <td>palace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where is a snake likely to startle a farmer?</th>\n",
       "      <td>[tropical forest, tree, pet shops, book store,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3. The correct answer is (E) field. A snake is...</td>\n",
       "      <td>3. the correct answer is (e) field. a snake is...</td>\n",
       "      <td>{'tropical forest': 127, 'tree': 146, 'book st...</td>\n",
       "      <td>tropical forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where is an apple tree likely found in abundance?</th>\n",
       "      <td>[south pole, park, vineyard, farmland, orchid]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. The correct answer is (E) orchard. An apple...</td>\n",
       "      <td>4. the correct answer is (e) orchard. an apple...</td>\n",
       "      <td>{'south pole': 140, 'park': 154, 'vineyard': 1...</td>\n",
       "      <td>south pole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where is someone likely to get cold on a balcony?</th>\n",
       "      <td>[theater, new orleans, michigan, theatre, anta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5. The correct answer is (E) Antarctica. A bal...</td>\n",
       "      <td>5. the correct answer is (e) antarctica. a bal...</td>\n",
       "      <td>{'theater': 238, 'new orleans': 249, 'michigan...</td>\n",
       "      <td>theater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Where is someone likely to store their comforter?</th>\n",
       "      <td>[livingroom, cedar chest, bedroom, world, livi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6. The correct answer is (B) cedar chest. A co...</td>\n",
       "      <td>6. the correct answer is (b) cedar chest. a co...</td>\n",
       "      <td>{'livingroom': 162, 'cedar chest': 29, 'bedroo...</td>\n",
       "      <td>cedar chest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9741 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           hypothesis  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  [park, coloring book, garden center, math prob...   \n",
       "A John is a bum.  Much like the stereotype, he ...  [bus depot, beach, train station, bridge, bridge]   \n",
       "A bad person places little value on being hones...  [excellent, upright, premium, competent, sincere]   \n",
       "A bald eagle flies over St. Paul, where is it?        [texas, thermal, minnesota, canada, photograph]   \n",
       "A battleship is a powerful vessel.  If you need...  [yatch, corvette, aircraft carrier, destroyer,...   \n",
       "...                                                                                               ...   \n",
       "Where is a pleasure garden likely to have orgin...  [fairy tale, resort town, english courtyard, p...   \n",
       "Where is a snake likely to startle a farmer?        [tropical forest, tree, pet shops, book store,...   \n",
       "Where is an apple tree likely found in abundance?      [south pole, park, vineyard, farmland, orchid]   \n",
       "Where is someone likely to get cold on a balcony?   [theater, new orleans, michigan, theatre, anta...   \n",
       "Where is someone likely to store their comforter?   [livingroom, cedar chest, bedroom, world, livi...   \n",
       "\n",
       "                                                                                               prompt  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  Questions: \"There are 10 apples on an apple tr...   \n",
       "A John is a bum.  Much like the stereotype, he ...  Questions: A John is a bum.  Much like the ste...   \n",
       "A bad person places little value on being hones...  Questions: A bad person places little value on...   \n",
       "A bald eagle flies over St. Paul, where is it?      Questions: A bald eagle flies over St. Paul, w...   \n",
       "A battleship is a powerful vessel.  If you need...  Questions: A battleship is a powerful vessel. ...   \n",
       "...                                                                                               ...   \n",
       "Where is a pleasure garden likely to have orgin...                                                NaN   \n",
       "Where is a snake likely to startle a farmer?                                                      NaN   \n",
       "Where is an apple tree likely found in abundance?                                                 NaN   \n",
       "Where is someone likely to get cold on a balcony?                                                 NaN   \n",
       "Where is someone likely to store their comforter?                                                 NaN   \n",
       "\n",
       "                                                                                            rationale  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  1. The correct answer is (D) math problem. Thi...   \n",
       "A John is a bum.  Much like the stereotype, he ...  2. The correct answer is (D) bridge. A John is...   \n",
       "A bad person places little value on being hones...  3. The correct answer is (E) sincere. A bad pe...   \n",
       "A bald eagle flies over St. Paul, where is it?      4. The correct answer is (C) minnesota. A bald...   \n",
       "A battleship is a powerful vessel.  If you need...  5. The correct answer is (D) destroyer. A batt...   \n",
       "...                                                                                               ...   \n",
       "Where is a pleasure garden likely to have orgin...  2. The correct answer is (D) palace. A pleasur...   \n",
       "Where is a snake likely to startle a farmer?        3. The correct answer is (E) field. A snake is...   \n",
       "Where is an apple tree likely found in abundance?   4. The correct answer is (E) orchard. An apple...   \n",
       "Where is someone likely to get cold on a balcony?   5. The correct answer is (E) Antarctica. A bal...   \n",
       "Where is someone likely to store their comforter?   6. The correct answer is (B) cedar chest. A co...   \n",
       "\n",
       "                                                                                                split  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  1. the correct answer is (d) math problem. thi...   \n",
       "A John is a bum.  Much like the stereotype, he ...  2. the correct answer is (d) bridge. a john is...   \n",
       "A bad person places little value on being hones...  3. the correct answer is (e) sincere. a bad pe...   \n",
       "A bald eagle flies over St. Paul, where is it?      4. the correct answer is (c) minnesota. a bald...   \n",
       "A battleship is a powerful vessel.  If you need...  5. the correct answer is (d) destroyer. a batt...   \n",
       "...                                                                                               ...   \n",
       "Where is a pleasure garden likely to have orgin...  2. the correct answer is (d) palace. a pleasur...   \n",
       "Where is a snake likely to startle a farmer?        3. the correct answer is (e) field. a snake is...   \n",
       "Where is an apple tree likely found in abundance?   4. the correct answer is (e) orchard. an apple...   \n",
       "Where is someone likely to get cold on a balcony?   5. the correct answer is (e) antarctica. a bal...   \n",
       "Where is someone likely to store their comforter?   6. the correct answer is (b) cedar chest. a co...   \n",
       "\n",
       "                                                                                        correct_index  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...                               {'math problem': 29}   \n",
       "A John is a bum.  Much like the stereotype, he ...                                     {'bridge': 29}   \n",
       "A bad person places little value on being hones...                                    {'sincere': 29}   \n",
       "A bald eagle flies over St. Paul, where is it?                                      {'minnesota': 29}   \n",
       "A battleship is a powerful vessel.  If you need...                                  {'destroyer': 29}   \n",
       "...                                                                                               ...   \n",
       "Where is a pleasure garden likely to have orgin...  {'fairy tale': 229, 'resort town': 243, 'engli...   \n",
       "Where is a snake likely to startle a farmer?        {'tropical forest': 127, 'tree': 146, 'book st...   \n",
       "Where is an apple tree likely found in abundance?   {'south pole': 140, 'park': 154, 'vineyard': 1...   \n",
       "Where is someone likely to get cold on a balcony?   {'theater': 238, 'new orleans': 249, 'michigan...   \n",
       "Where is someone likely to store their comforter?   {'livingroom': 162, 'cedar chest': 29, 'bedroo...   \n",
       "\n",
       "                                                         LLM_answer  \n",
       "premise                                                              \n",
       "\"There are 10 apples on an apple tree.  Three f...     math problem  \n",
       "A John is a bum.  Much like the stereotype, he ...           bridge  \n",
       "A bad person places little value on being hones...          sincere  \n",
       "A bald eagle flies over St. Paul, where is it?            minnesota  \n",
       "A battleship is a powerful vessel.  If you need...        destroyer  \n",
       "...                                                             ...  \n",
       "Where is a pleasure garden likely to have orgin...           palace  \n",
       "Where is a snake likely to startle a farmer?        tropical forest  \n",
       "Where is an apple tree likely found in abundance?        south pole  \n",
       "Where is someone likely to get cold on a balcony?           theater  \n",
       "Where is someone likely to store their comforter?       cedar chest  \n",
       "\n",
       "[9741 rows x 6 columns]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
