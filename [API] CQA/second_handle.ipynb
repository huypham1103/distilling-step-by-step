{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'historical.csv'\n",
    "df = pd.read_csv(path, index_col=0)[['premise', 'hypothesis', 'prompt', 'rationale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hypothesis'] = df['hypothesis'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rationale = df.rationale.astype(str)\n",
    "df['split'] = df.rationale.apply(lambda x: x.lower().split('most likely answer'))\n",
    "df.split = df.split.apply(lambda x : x[1] if len(x) > 1 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The morbidly obese man with unkempt facial hai...</td>\n",
       "      <td>[french fries, enjoy, nausea, satisfaction, gas]</td>\n",
       "      <td>Questions: The morbidly obese man with unkempt...</td>\n",
       "      <td>1. The most likely answer is **(D) satisfactio...</td>\n",
       "      <td>is **(d) satisfaction**. the question is base...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  The morbidly obese man with unkempt facial hai...   \n",
       "\n",
       "                                         hypothesis  \\\n",
       "0  [french fries, enjoy, nausea, satisfaction, gas]   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Questions: The morbidly obese man with unkempt...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  1. The most likely answer is **(D) satisfactio...   \n",
       "\n",
       "                                               split  \n",
       "0   is **(d) satisfaction**. the question is base...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct index\n",
    "df['correct_index'] = [{} for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    for choice in row['hypothesis']:\n",
    "        if choice in row['split']:\n",
    "            row['correct_index'][choice] = row['split'].lower().index(choice.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM_answer'] = df.correct_index.apply(lambda x: min(x, key=x.get) if len(x) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read paper's answer\n",
    "paper = pd.read_csv('paper.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['premise'] = paper.input.str.split('\\n').apply(lambda x: x[0])\n",
    "paper.set_index('premise', inplace=True)\n",
    "paper.index = paper.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('premise', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['my_label'] = df['LLM_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074119700236115"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(paper.label == paper.my_label) / len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('historical - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>The child was taken against its will and what ...</td>\n",
       "      <td>['for or', 'away from', 'being for', 'because'...</td>\n",
       "      <td>Questions: The child was taken against its wil...</td>\n",
       "      <td>\\nThe most likely answer to the question \"The ...</td>\n",
       "      <td>6th century and spread to europe and asia thro...</td>\n",
       "      <td>{'because': 1134}</td>\n",
       "      <td>because</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>People often have to take medicine, they tend ...</td>\n",
       "      <td>['kitchen', \"doctor's office\", 'hospital', 'ba...</td>\n",
       "      <td>Questions: People often have to take medicine,...</td>\n",
       "      <td>\\nThe most likely answer to the question \"Peop...</td>\n",
       "      <td>to the question 'people keep their teddy bear...</td>\n",
       "      <td>{'kitchen': 266, 'bathroom': 281}</td>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>How is a soldier likely to travel?</td>\n",
       "      <td>['carriage', 'armored car', 'trenches', 'tent'...</td>\n",
       "      <td>Questions: How is a soldier likely to travel?,...</td>\n",
       "      <td>The most likely answer to the question \"How is...</td>\n",
       "      <td>to the question 'how does one decide if insti...</td>\n",
       "      <td>{'tent': 976}</td>\n",
       "      <td>tent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>Where would you put your change if you plan to...</td>\n",
       "      <td>['backseat of car', 'purse', 'pocket', 'jar', ...</td>\n",
       "      <td>Questions: Where would you put your change if ...</td>\n",
       "      <td>\\nThe most likely answer to the question \"Wher...</td>\n",
       "      <td>is **(a) stores along beach**. stores along b...</td>\n",
       "      <td>{'pocket': 524}</td>\n",
       "      <td>pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>Dan found a bunch of ball bearings behind a wa...</td>\n",
       "      <td>['high quality motor', 'skatepark', 'machines'...</td>\n",
       "      <td>Questions: Dan found a bunch of ball bearings ...</td>\n",
       "      <td>\\nThe most likely answer to the question \"Dan ...</td>\n",
       "      <td>to the question 'contemplating a concept can ...</td>\n",
       "      <td>{'can': 42}</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>where do you typically buy apples?</td>\n",
       "      <td>['farmers market', 'table', 'grocery store', '...</td>\n",
       "      <td>Questions: where do you typically buy apples?,...</td>\n",
       "      <td>The most likely answer to the question \"Where ...</td>\n",
       "      <td>to the question 'where do you buy the freshes...</td>\n",
       "      <td>{'farmers market': 66, 'grocery store': 488, '...</td>\n",
       "      <td>farmers market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>Where is the last place food is before being e...</td>\n",
       "      <td>['kitchen', 'plate', 'dinning', 'stomach', 'pa...</td>\n",
       "      <td>Questions: Where is the last place food is bef...</td>\n",
       "      <td>\\nThe most likely answer to the question \"Wher...</td>\n",
       "      <td>is **(d) body**. the flu is a contagious resp...</td>\n",
       "      <td>{'stomach': 608}</td>\n",
       "      <td>stomach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7841</th>\n",
       "      <td>The Mormon owned steak house was always busy, ...</td>\n",
       "      <td>['utah', 'nebraska', 'the sun', 'new york', 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nThe most likely answer to the question \"The ...</td>\n",
       "      <td>is **(e) new mexico**. the canadian was trave...</td>\n",
       "      <td>{'utah': 198}</td>\n",
       "      <td>utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8423</th>\n",
       "      <td>The peaceful nation was scared of their neighb...</td>\n",
       "      <td>['violent', 'warring', 'eferendum because thei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nThe most likely answer to the question \"The ...</td>\n",
       "      <td>7 french presidential election, some voters ch...</td>\n",
       "      <td>{'violent': 1152}</td>\n",
       "      <td>belligerent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8868</th>\n",
       "      <td>What high rise is often made of windows?</td>\n",
       "      <td>['warehouse', \"friend's house\", 'building', 's...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most likely answer to the question \"What h...</td>\n",
       "      <td>is **(d) match**. this is a term that refers ...</td>\n",
       "      <td>{'wall': 338}</td>\n",
       "      <td>building</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "166   The child was taken against its will and what ...   \n",
       "2164  People often have to take medicine, they tend ...   \n",
       "2729                 How is a soldier likely to travel?   \n",
       "4368  Where would you put your change if you plan to...   \n",
       "4453  Dan found a bunch of ball bearings behind a wa...   \n",
       "6166                 where do you typically buy apples?   \n",
       "7332  Where is the last place food is before being e...   \n",
       "7841  The Mormon owned steak house was always busy, ...   \n",
       "8423  The peaceful nation was scared of their neighb...   \n",
       "8868           What high rise is often made of windows?   \n",
       "\n",
       "                                             hypothesis  \\\n",
       "166   ['for or', 'away from', 'being for', 'because'...   \n",
       "2164  ['kitchen', \"doctor's office\", 'hospital', 'ba...   \n",
       "2729  ['carriage', 'armored car', 'trenches', 'tent'...   \n",
       "4368  ['backseat of car', 'purse', 'pocket', 'jar', ...   \n",
       "4453  ['high quality motor', 'skatepark', 'machines'...   \n",
       "6166  ['farmers market', 'table', 'grocery store', '...   \n",
       "7332  ['kitchen', 'plate', 'dinning', 'stomach', 'pa...   \n",
       "7841  ['utah', 'nebraska', 'the sun', 'new york', 's...   \n",
       "8423  ['violent', 'warring', 'eferendum because thei...   \n",
       "8868  ['warehouse', \"friend's house\", 'building', 's...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "166   Questions: The child was taken against its wil...   \n",
       "2164  Questions: People often have to take medicine,...   \n",
       "2729  Questions: How is a soldier likely to travel?,...   \n",
       "4368  Questions: Where would you put your change if ...   \n",
       "4453  Questions: Dan found a bunch of ball bearings ...   \n",
       "6166  Questions: where do you typically buy apples?,...   \n",
       "7332  Questions: Where is the last place food is bef...   \n",
       "7841                                                NaN   \n",
       "8423                                                NaN   \n",
       "8868                                                NaN   \n",
       "\n",
       "                                              rationale  \\\n",
       "166   \\nThe most likely answer to the question \"The ...   \n",
       "2164  \\nThe most likely answer to the question \"Peop...   \n",
       "2729  The most likely answer to the question \"How is...   \n",
       "4368  \\nThe most likely answer to the question \"Wher...   \n",
       "4453  \\nThe most likely answer to the question \"Dan ...   \n",
       "6166  The most likely answer to the question \"Where ...   \n",
       "7332  \\nThe most likely answer to the question \"Wher...   \n",
       "7841  \\nThe most likely answer to the question \"The ...   \n",
       "8423  \\nThe most likely answer to the question \"The ...   \n",
       "8868  The most likely answer to the question \"What h...   \n",
       "\n",
       "                                                  split  \\\n",
       "166   6th century and spread to europe and asia thro...   \n",
       "2164   to the question 'people keep their teddy bear...   \n",
       "2729   to the question 'how does one decide if insti...   \n",
       "4368   is **(a) stores along beach**. stores along b...   \n",
       "4453   to the question 'contemplating a concept can ...   \n",
       "6166   to the question 'where do you buy the freshes...   \n",
       "7332   is **(d) body**. the flu is a contagious resp...   \n",
       "7841   is **(e) new mexico**. the canadian was trave...   \n",
       "8423  7 french presidential election, some voters ch...   \n",
       "8868   is **(d) match**. this is a term that refers ...   \n",
       "\n",
       "                                          correct_index      LLM_answer  \n",
       "166                                   {'because': 1134}         because  \n",
       "2164                  {'kitchen': 266, 'bathroom': 281}         kitchen  \n",
       "2729                                      {'tent': 976}            tent  \n",
       "4368                                    {'pocket': 524}          pocket  \n",
       "4453                                        {'can': 42}             can  \n",
       "6166  {'farmers market': 66, 'grocery store': 488, '...  farmers market  \n",
       "7332                                   {'stomach': 608}         stomach  \n",
       "7841                                      {'utah': 198}            utah  \n",
       "8423                                  {'violent': 1152}     belligerent  \n",
       "8868                                      {'wall': 338}        building  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE = 'historical'\n",
    "temp = pd.read_csv(f'{TYPE} - full.csv')\n",
    "\n",
    "import re\n",
    "temp[~temp['rationale'].apply(lambda x: bool(re.match(r'\\d+\\.', x.strip())))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
