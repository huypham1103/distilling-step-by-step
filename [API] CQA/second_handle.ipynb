{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'if_else.csv'\n",
    "df = pd.read_csv(path, index_col=0)[['premise', 'hypothesis', 'prompt', 'rationale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hypothesis'] = df['hypothesis'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rationale = df.rationale.astype(str)\n",
    "df['split'] = df.rationale.apply(lambda x: x.lower().split('most likely answer'))\n",
    "df.split = df.split.apply(lambda x : x[1] if len(x) > 1 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where could you find a person standing next to...</td>\n",
       "      <td>[ocean, soccer game, fishing gear, fisherman's...</td>\n",
       "      <td>Questions: Where could you find a person stand...</td>\n",
       "      <td>1. The correct answer is **(B) soccer game**. ...</td>\n",
       "      <td>1. the correct answer is **(b) soccer game**. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Where could you find a person standing next to...   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  [ocean, soccer game, fishing gear, fisherman's...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Questions: Where could you find a person stand...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  1. The correct answer is **(B) soccer game**. ...   \n",
       "\n",
       "                                               split  \n",
       "0  1. the correct answer is **(b) soccer game**. ...  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct index\n",
    "df['correct_index'] = [{} for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    for choice in row['hypothesis']:\n",
    "        if choice in row['split']:\n",
    "            row['correct_index'][choice] = row['split'].lower().index(choice.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM_answer'] = df.correct_index.apply(lambda x: min(x, key=x.get) if len(x) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Where could you find millions of jellyfish?</td>\n",
       "      <td>[north sea, smack, sponge bob's house, store, ...</td>\n",
       "      <td>Questions: Where could you find millions of je...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Where could you find more than a few bald eagle?</td>\n",
       "      <td>[the park, in washington, eagle's nest, aerie,...</td>\n",
       "      <td>Questions: Where could you find more than a fe...</td>\n",
       "      <td>9th and 20th centuries, and they are considere...</td>\n",
       "      <td>9th and 20th centuries, and they are considere...</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Where could you find multiple ruler that are o...</td>\n",
       "      <td>[measure distance, england, office, drawer, desk]</td>\n",
       "      <td>Questions: Where could you find multiple ruler...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Joe and Jane have begun reaching a tentative a...</td>\n",
       "      <td>[compromises, eloping, calmness, fucking, hand...</td>\n",
       "      <td>Questions: Joe and Jane have begun reaching a ...</td>\n",
       "      <td>1. The correct answer is (D) fuckin</td>\n",
       "      <td>1. the correct answer is (d) fuckin</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Joe and Jim were running errands together.  Th...</td>\n",
       "      <td>[stress, aggravation, efficiency, tiredness, n...</td>\n",
       "      <td>Questions: Joe and Jim were running errands to...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>She always made sure her infant was sleeping t...</td>\n",
       "      <td>[nightmares, death, dreams, erections, vaccines]</td>\n",
       "      <td>Questions: She always made sure her infant was...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>She always wondered how safe it was to use her...</td>\n",
       "      <td>[jungle, drug store, box, beauty salon, bathroom]</td>\n",
       "      <td>Questions: She always wondered how safe it was...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9639</th>\n",
       "      <td>She asked to swallow semen, he shrugged and re...</td>\n",
       "      <td>[you're into, prostitute, in a porn movie, por...</td>\n",
       "      <td>Questions: She asked to swallow semen, he shru...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>She began to play violin at a young age, she h...</td>\n",
       "      <td>[inspiring, like music, be musician, make musi...</td>\n",
       "      <td>Questions: She began to play violin at a young...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>What geological feature is made mostly of rock?</td>\n",
       "      <td>[countryside, ground, street, mountain range, ...</td>\n",
       "      <td>Questions: What geological feature is made mos...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "27          Where could you find millions of jellyfish?   \n",
       "28     Where could you find more than a few bald eagle?   \n",
       "29    Where could you find multiple ruler that are o...   \n",
       "260   Joe and Jane have begun reaching a tentative a...   \n",
       "261   Joe and Jim were running errands together.  Th...   \n",
       "...                                                 ...   \n",
       "9637  She always made sure her infant was sleeping t...   \n",
       "9638  She always wondered how safe it was to use her...   \n",
       "9639  She asked to swallow semen, he shrugged and re...   \n",
       "9640  She began to play violin at a young age, she h...   \n",
       "9718    What geological feature is made mostly of rock?   \n",
       "\n",
       "                                             hypothesis  \\\n",
       "27    [north sea, smack, sponge bob's house, store, ...   \n",
       "28    [the park, in washington, eagle's nest, aerie,...   \n",
       "29    [measure distance, england, office, drawer, desk]   \n",
       "260   [compromises, eloping, calmness, fucking, hand...   \n",
       "261   [stress, aggravation, efficiency, tiredness, n...   \n",
       "...                                                 ...   \n",
       "9637   [nightmares, death, dreams, erections, vaccines]   \n",
       "9638  [jungle, drug store, box, beauty salon, bathroom]   \n",
       "9639  [you're into, prostitute, in a porn movie, por...   \n",
       "9640  [inspiring, like music, be musician, make musi...   \n",
       "9718  [countryside, ground, street, mountain range, ...   \n",
       "\n",
       "                                                 prompt  \\\n",
       "27    Questions: Where could you find millions of je...   \n",
       "28    Questions: Where could you find more than a fe...   \n",
       "29    Questions: Where could you find multiple ruler...   \n",
       "260   Questions: Joe and Jane have begun reaching a ...   \n",
       "261   Questions: Joe and Jim were running errands to...   \n",
       "...                                                 ...   \n",
       "9637  Questions: She always made sure her infant was...   \n",
       "9638  Questions: She always wondered how safe it was...   \n",
       "9639  Questions: She asked to swallow semen, he shru...   \n",
       "9640  Questions: She began to play violin at a young...   \n",
       "9718  Questions: What geological feature is made mos...   \n",
       "\n",
       "                                              rationale  \\\n",
       "27                                                  nan   \n",
       "28    9th and 20th centuries, and they are considere...   \n",
       "29                                                    b   \n",
       "260                 1. The correct answer is (D) fuckin   \n",
       "261                                                 nan   \n",
       "...                                                 ...   \n",
       "9637                                                nan   \n",
       "9638                                                nan   \n",
       "9639                                                nan   \n",
       "9640                                                  2   \n",
       "9718                                                nan   \n",
       "\n",
       "                                                  split correct_index  \\\n",
       "27                                                  nan            {}   \n",
       "28    9th and 20th centuries, and they are considere...            {}   \n",
       "29                                                    b            {}   \n",
       "260                 1. the correct answer is (d) fuckin            {}   \n",
       "261                                                 nan            {}   \n",
       "...                                                 ...           ...   \n",
       "9637                                                nan            {}   \n",
       "9638                                                nan            {}   \n",
       "9639                                                nan            {}   \n",
       "9640                                                  2            {}   \n",
       "9718                                                nan            {}   \n",
       "\n",
       "     LLM_answer  \n",
       "27          NaN  \n",
       "28          NaN  \n",
       "29          NaN  \n",
       "260         NaN  \n",
       "261         NaN  \n",
       "...         ...  \n",
       "9637        NaN  \n",
       "9638        NaN  \n",
       "9639        NaN  \n",
       "9640        NaN  \n",
       "9718        NaN  \n",
       "\n",
       "[428 rows x 7 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read paper's answer\n",
    "paper = pd.read_csv('/home/huy/Desktop/HCMUS/distilling-step-by-step/[API] CQA/paper.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = pd.read_csv('/home/huy/Desktop/HCMUS/distilling-step-by-step/[API] CQA/consensus - full.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['premise'] = paper.input.str.split('\\n').apply(lambda x: x[0])\n",
    "paper.set_index('premise', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['premise'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-84900ce804cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'premise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/huy/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/huy/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6012\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['premise'] are in the columns\""
     ]
    }
   ],
   "source": [
    "df.set_index('premise', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['my_label'] = consensus['LLM_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7465352633199877"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(paper.label == paper.my_label) / len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('neutral - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>rationales</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?</th>\n",
       "      <td>['park', 'coloring book', 'garden center', 'ma...</td>\n",
       "      <td>1. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>1. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'math problem': 163}</td>\n",
       "      <td>math problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A John is a bum.  Much like the stereotype, he lives near this sort of transportation infrastructure. Where does he live?</th>\n",
       "      <td>['bus depot', 'beach', 'train station', 'bridg...</td>\n",
       "      <td>2. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>2. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'bridge': 179}</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A bad person places little value on being honest, acting without pretense or being what?</th>\n",
       "      <td>['excellent', 'upright', 'premium', 'competent...</td>\n",
       "      <td>3. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>3. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'sincere': 145}</td>\n",
       "      <td>sincere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A bald eagle flies over St. Paul, where is it?</th>\n",
       "      <td>['texas', 'thermal', 'minnesota', 'canada', 'p...</td>\n",
       "      <td>4. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>4. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'minnesota': 103}</td>\n",
       "      <td>minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A battleship is a powerful vessel.  If you need something similar but faster, what would you use?</th>\n",
       "      <td>['yatch', 'corvette', 'aircraft carrier', 'des...</td>\n",
       "      <td>5. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>5. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'destroyer': 155}</td>\n",
       "      <td>destroyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where is the information superhighway?</th>\n",
       "      <td>['heavily travelled area', 'cyberspace', 'indu...</td>\n",
       "      <td>7. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>7. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'cyberspace': 99}</td>\n",
       "      <td>cyberspace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where would a good newspaper boy put a paper in the rain?</th>\n",
       "      <td>['library', 'lawn', 'trash', 'roof', 'front do...</td>\n",
       "      <td>8. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>8. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'front door': 118}</td>\n",
       "      <td>front door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which door with lock regularly holds cars?</th>\n",
       "      <td>['house', 'autolock', 'garage', 'file cabinet'...</td>\n",
       "      <td>9. The commonly agreed-upon answer to the ques...</td>\n",
       "      <td>9. the commonly agreed-upon answer to the ques...</td>\n",
       "      <td>{'garage': 103}</td>\n",
       "      <td>garage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which half of the earth do marmots live in?</th>\n",
       "      <td>['south', 'northern hemisphere', 'north americ...</td>\n",
       "      <td>10. The commonly agreed-upon answer to the que...</td>\n",
       "      <td>10. the commonly agreed-upon answer to the que...</td>\n",
       "      <td>{'northern hemisphere': 105, 'north america': ...</td>\n",
       "      <td>northern hemisphere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who uses a contraceptive device?</th>\n",
       "      <td>['pharmacy', 'bedroom', 'person', 'men', 'drug...</td>\n",
       "      <td>The correct answer to this question is (C) per...</td>\n",
       "      <td>the correct answer to this question is (c) per...</td>\n",
       "      <td>{'person': 43}</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9741 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           hypothesis  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  ['park', 'coloring book', 'garden center', 'ma...   \n",
       "A John is a bum.  Much like the stereotype, he ...  ['bus depot', 'beach', 'train station', 'bridg...   \n",
       "A bad person places little value on being hones...  ['excellent', 'upright', 'premium', 'competent...   \n",
       "A bald eagle flies over St. Paul, where is it?      ['texas', 'thermal', 'minnesota', 'canada', 'p...   \n",
       "A battleship is a powerful vessel.  If you need...  ['yatch', 'corvette', 'aircraft carrier', 'des...   \n",
       "...                                                                                               ...   \n",
       "where is the information superhighway?              ['heavily travelled area', 'cyberspace', 'indu...   \n",
       "where would a good newspaper boy put a paper in...  ['library', 'lawn', 'trash', 'roof', 'front do...   \n",
       "which door with lock regularly holds cars?          ['house', 'autolock', 'garage', 'file cabinet'...   \n",
       "which half of the earth do marmots live in?         ['south', 'northern hemisphere', 'north americ...   \n",
       "who uses a contraceptive device?                    ['pharmacy', 'bedroom', 'person', 'men', 'drug...   \n",
       "\n",
       "                                                                                           rationales  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  1. The commonly agreed-upon answer to the ques...   \n",
       "A John is a bum.  Much like the stereotype, he ...  2. The commonly agreed-upon answer to the ques...   \n",
       "A bad person places little value on being hones...  3. The commonly agreed-upon answer to the ques...   \n",
       "A bald eagle flies over St. Paul, where is it?      4. The commonly agreed-upon answer to the ques...   \n",
       "A battleship is a powerful vessel.  If you need...  5. The commonly agreed-upon answer to the ques...   \n",
       "...                                                                                               ...   \n",
       "where is the information superhighway?              7. The commonly agreed-upon answer to the ques...   \n",
       "where would a good newspaper boy put a paper in...  8. The commonly agreed-upon answer to the ques...   \n",
       "which door with lock regularly holds cars?          9. The commonly agreed-upon answer to the ques...   \n",
       "which half of the earth do marmots live in?         10. The commonly agreed-upon answer to the que...   \n",
       "who uses a contraceptive device?                    The correct answer to this question is (C) per...   \n",
       "\n",
       "                                                                                                split  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...  1. the commonly agreed-upon answer to the ques...   \n",
       "A John is a bum.  Much like the stereotype, he ...  2. the commonly agreed-upon answer to the ques...   \n",
       "A bad person places little value on being hones...  3. the commonly agreed-upon answer to the ques...   \n",
       "A bald eagle flies over St. Paul, where is it?      4. the commonly agreed-upon answer to the ques...   \n",
       "A battleship is a powerful vessel.  If you need...  5. the commonly agreed-upon answer to the ques...   \n",
       "...                                                                                               ...   \n",
       "where is the information superhighway?              7. the commonly agreed-upon answer to the ques...   \n",
       "where would a good newspaper boy put a paper in...  8. the commonly agreed-upon answer to the ques...   \n",
       "which door with lock regularly holds cars?          9. the commonly agreed-upon answer to the ques...   \n",
       "which half of the earth do marmots live in?         10. the commonly agreed-upon answer to the que...   \n",
       "who uses a contraceptive device?                    the correct answer to this question is (c) per...   \n",
       "\n",
       "                                                                                        correct_index  \\\n",
       "premise                                                                                                 \n",
       "\"There are 10 apples on an apple tree.  Three f...                              {'math problem': 163}   \n",
       "A John is a bum.  Much like the stereotype, he ...                                    {'bridge': 179}   \n",
       "A bad person places little value on being hones...                                   {'sincere': 145}   \n",
       "A bald eagle flies over St. Paul, where is it?                                     {'minnesota': 103}   \n",
       "A battleship is a powerful vessel.  If you need...                                 {'destroyer': 155}   \n",
       "...                                                                                               ...   \n",
       "where is the information superhighway?                                             {'cyberspace': 99}   \n",
       "where would a good newspaper boy put a paper in...                                {'front door': 118}   \n",
       "which door with lock regularly holds cars?                                            {'garage': 103}   \n",
       "which half of the earth do marmots live in?         {'northern hemisphere': 105, 'north america': ...   \n",
       "who uses a contraceptive device?                                                       {'person': 43}   \n",
       "\n",
       "                                                             LLM_answer  \n",
       "premise                                                                  \n",
       "\"There are 10 apples on an apple tree.  Three f...         math problem  \n",
       "A John is a bum.  Much like the stereotype, he ...               bridge  \n",
       "A bad person places little value on being hones...              sincere  \n",
       "A bald eagle flies over St. Paul, where is it?                minnesota  \n",
       "A battleship is a powerful vessel.  If you need...            destroyer  \n",
       "...                                                                 ...  \n",
       "where is the information superhighway?                       cyberspace  \n",
       "where would a good newspaper boy put a paper in...           front door  \n",
       "which door with lock regularly holds cars?                       garage  \n",
       "which half of the earth do marmots live in?         northern hemisphere  \n",
       "who uses a contraceptive device?                                 person  \n",
       "\n",
       "[9741 rows x 5 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
