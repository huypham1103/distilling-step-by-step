{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'comparative.csv'\n",
    "df = pd.read_csv(path, index_col=0)[['premise', 'hypothesis', 'prompt', 'rationale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rationale = df.rationale.astype(str)\n",
    "df['split'] = df.rationale.apply(lambda x: x.lower().split('most likely answer'))\n",
    "df.split = df.split.apply(lambda x : x[1] if len(x) > 1 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man in orange shorts sits on some steps in f...</td>\n",
       "      <td>A man in shorts sits on some steps.</td>\n",
       "      <td>Premise: A man in orange shorts sits on some s...</td>\n",
       "      <td>1. The most likely answer is **entailment**. T...</td>\n",
       "      <td>is **entailment**. this means that the hypoth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  A man in orange shorts sits on some steps in f...   \n",
       "\n",
       "                            hypothesis  \\\n",
       "0  A man in shorts sits on some steps.   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Premise: A man in orange shorts sits on some s...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  1. The most likely answer is **entailment**. T...   \n",
       "\n",
       "                                               split  \n",
       "0   is **entailment**. this means that the hypoth...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct index\n",
    "df['correct_index'] = [{} for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    for choice in [\"entailment\", \"neutral\", \"contradiction\", 'entailed', 'contradicts', 'entails', 'contradicted', 'contradictory']:\n",
    "        if choice in row['split']:\n",
    "            row['correct_index'][choice] = row['split'].lower().index(choice.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM_answer'] = df.correct_index.apply(lambda x: min(x, key=x.get) if len(x) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>llm_label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The person could be training his horse for a c...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The person on the horse is not at the diner.</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The person is outdoors because the airplane is...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>They are smiling at the camera, not their pare...</td>\n",
       "      <td>Children smiling and waving at camera&lt;/s&gt;They ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The children are present because they are smil...</td>\n",
       "      <td>Children smiling and waving at camera&lt;/s&gt;There...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>A baby in a white and light purple outfit crying.</td>\n",
       "      <td>A baby is crying because it is hungry.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The baby is crying, but it is not necessarily ...</td>\n",
       "      <td>A baby in a white and light purple outfit cryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The baby is sleeping peacefully.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The baby is crying, not sleeping.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The baby is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The child is under three years old.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The child is a baby.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The baby is a girl.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The baby is wearing a purple onesie.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The baby is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A dog running in the grass.</td>\n",
       "      <td>The dog is lying in the bedroom.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The dog is running in the grass, not lying in ...</td>\n",
       "      <td>A dog running in the grass.&lt;/s&gt;The dog is lyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     A person on a horse jumps over a broken down a...   \n",
       "1     A person on a horse jumps over a broken down a...   \n",
       "2     A person on a horse jumps over a broken down a...   \n",
       "3                 Children smiling and waving at camera   \n",
       "4                 Children smiling and waving at camera   \n",
       "...                                                 ...   \n",
       "9995  A baby in a white and light purple outfit crying.   \n",
       "9996                    Baby in a purple onesie crying.   \n",
       "9997                    Baby in a purple onesie crying.   \n",
       "9998                    Baby in a purple onesie crying.   \n",
       "9999                        A dog running in the grass.   \n",
       "\n",
       "                                             hypothesis          label  \\\n",
       "0     A person is training his horse for a competition.        neutral   \n",
       "1         A person is at a diner, ordering an omelette.  contradiction   \n",
       "2                     A person is outdoors, on a horse.     entailment   \n",
       "3                     They are smiling at their parents        neutral   \n",
       "4                            There are children present     entailment   \n",
       "...                                                 ...            ...   \n",
       "9995             A baby is crying because it is hungry.        neutral   \n",
       "9996                   The baby is sleeping peacefully.  contradiction   \n",
       "9997                The child is under three years old.     entailment   \n",
       "9998                                The baby is a girl.        neutral   \n",
       "9999                   The dog is lying in the bedroom.  contradiction   \n",
       "\n",
       "          llm_label                                          rationale  \\\n",
       "0           neutral  The person could be training his horse for a c...   \n",
       "1     contradiction       The person on the horse is not at the diner.   \n",
       "2        entailment  The person is outdoors because the airplane is...   \n",
       "3           neutral  They are smiling at the camera, not their pare...   \n",
       "4        entailment  The children are present because they are smil...   \n",
       "...             ...                                                ...   \n",
       "9995        neutral  The baby is crying, but it is not necessarily ...   \n",
       "9996  contradiction                  The baby is crying, not sleeping.   \n",
       "9997     entailment                               The child is a baby.   \n",
       "9998        neutral               The baby is wearing a purple onesie.   \n",
       "9999  contradiction  The dog is running in the grass, not lying in ...   \n",
       "\n",
       "                                                  input  \n",
       "0     A person on a horse jumps over a broken down a...  \n",
       "1     A person on a horse jumps over a broken down a...  \n",
       "2     A person on a horse jumps over a broken down a...  \n",
       "3     Children smiling and waving at camera</s>They ...  \n",
       "4     Children smiling and waving at camera</s>There...  \n",
       "...                                                 ...  \n",
       "9995  A baby in a white and light purple outfit cryi...  \n",
       "9996  Baby in a purple onesie crying.</s>The baby is...  \n",
       "9997  Baby in a purple onesie crying.</s>The child i...  \n",
       "9998  Baby in a purple onesie crying.</s>The baby is...  \n",
       "9999  A dog running in the grass.</s>The dog is lyin...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read paper's answer\n",
    "paper = pd.read_csv('paper.csv', index_col=0)\n",
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper['premise'] = paper.input.str.split('\\n').apply(lambda x: x[0])\n",
    "paper.set_index(['premise', 'hypothesis'], inplace=True)\n",
    "# paper.index = paper.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['premise', 'hypothesis'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['my_label'] = df['LLM_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8656"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(paper.label == paper.my_label) / len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('comparative - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>A young woman is drawing with a Sharpie marker.</td>\n",
       "      <td>A woman is drawing.</td>\n",
       "      <td>Premise: A young woman is drawing with a Sharp...</td>\n",
       "      <td>For the premise \"A young woman is drawing with...</td>\n",
       "      <td>is also **entailment**. this means that the h...</td>\n",
       "      <td>{'entailment': 11}</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>A greyhound runs in a race, bee striped jacket...</td>\n",
       "      <td>The greyhound is extremely fast.</td>\n",
       "      <td>Premise: A greyhound runs in a race, bee strip...</td>\n",
       "      <td>For the premise \"A greyhound runs in a race, b...</td>\n",
       "      <td>is **contradiction**. this means that the hyp...</td>\n",
       "      <td>{'contradiction': 6}</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "2176    A young woman is drawing with a Sharpie marker.   \n",
       "4384  A greyhound runs in a race, bee striped jacket...   \n",
       "\n",
       "                            hypothesis  \\\n",
       "2176               A woman is drawing.   \n",
       "4384  The greyhound is extremely fast.   \n",
       "\n",
       "                                                 prompt  \\\n",
       "2176  Premise: A young woman is drawing with a Sharp...   \n",
       "4384  Premise: A greyhound runs in a race, bee strip...   \n",
       "\n",
       "                                              rationale  \\\n",
       "2176  For the premise \"A young woman is drawing with...   \n",
       "4384  For the premise \"A greyhound runs in a race, b...   \n",
       "\n",
       "                                                  split         correct_index  \\\n",
       "2176   is also **entailment**. this means that the h...    {'entailment': 11}   \n",
       "4384   is **contradiction**. this means that the hyp...  {'contradiction': 6}   \n",
       "\n",
       "         LLM_answer  \n",
       "2176     entailment  \n",
       "4384  contradiction  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "TYPE = 'contrastive'\n",
    "temp = pd.read_csv(f'{TYPE} - full.csv')\n",
    "\n",
    "import re\n",
    "temp[~temp['rationale'].apply(lambda x: bool(re.match(r'\\d+\\.', x.strip())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          3472\n",
       "entailment       3398\n",
       "contradiction    3120\n",
       "Name: LLM_answer, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.LLM_answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "temp = pd.read_csv('D:\\distilling-step-by-step\\[API] ESNLI\\paper.csv', index_col=0).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.rename(columns={'llm_label': 'LLM_answer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['premise', 'hypothesis', 'LLM_answer', 'rationale']].dropna().reset_index().to_csv('paper - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read causal full csv\n",
    "causal = pd.read_csv('causal - full.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal[causal.rationale.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of paper not in causal\n",
    "temp.set_index(['premise', 'hypothesis'], inplace=True)\n",
    "causal.set_index(['premise', 'hypothesis'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[~temp.index.isin(causal.index)].reset_index().to_csv('error.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
