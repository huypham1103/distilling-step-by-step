{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'historical.csv'\n",
    "df = pd.read_csv(path, index_col=0)[['premise', 'hypothesis', 'prompt', 'rationale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rationale = df.rationale.astype(str)\n",
    "df['split'] = df.rationale.apply(lambda x: x.lower().split('most likely answer'))\n",
    "df.split = df.split.apply(lambda x : x[1] if len(x) > 1 else x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An older man in jeans and a sweater is lifting...</td>\n",
       "      <td>The man is looking for something in the boxes.</td>\n",
       "      <td>Premise: An older man in jeans and a sweater i...</td>\n",
       "      <td>1. The most likely answer is **neutral**. The ...</td>\n",
       "      <td>is **neutral**. the premise does not provide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  An older man in jeans and a sweater is lifting...   \n",
       "\n",
       "                                       hypothesis  \\\n",
       "0  The man is looking for something in the boxes.   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Premise: An older man in jeans and a sweater i...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  1. The most likely answer is **neutral**. The ...   \n",
       "\n",
       "                                               split  \n",
       "0   is **neutral**. the premise does not provide ...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get correct index\n",
    "df['correct_index'] = [{} for _ in range(len(df))]\n",
    "for index, row in df.iterrows():\n",
    "    for choice in [\"entailment\", \"neutral\", \"contradiction\", 'entailed', 'contradicts', 'entails', 'contradicted', 'contradictory']:\n",
    "        if choice in row['split']:\n",
    "            row['correct_index'][choice] = row['split'].lower().index(choice.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LLM_answer'] = df.correct_index.apply(lambda x: min(x, key=x.get) if len(x) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>llm_label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The person could be training his horse for a c...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The person on the horse is not at the diner.</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The person is outdoors because the airplane is...</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>They are smiling at the camera, not their pare...</td>\n",
       "      <td>Children smiling and waving at camera&lt;/s&gt;They ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The children are present because they are smil...</td>\n",
       "      <td>Children smiling and waving at camera&lt;/s&gt;There...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>A baby in a white and light purple outfit crying.</td>\n",
       "      <td>A baby is crying because it is hungry.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The baby is crying, but it is not necessarily ...</td>\n",
       "      <td>A baby in a white and light purple outfit cryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The baby is sleeping peacefully.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The baby is crying, not sleeping.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The baby is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The child is under three years old.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment</td>\n",
       "      <td>The child is a baby.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The child i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Baby in a purple onesie crying.</td>\n",
       "      <td>The baby is a girl.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The baby is wearing a purple onesie.</td>\n",
       "      <td>Baby in a purple onesie crying.&lt;/s&gt;The baby is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>A dog running in the grass.</td>\n",
       "      <td>The dog is lying in the bedroom.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>The dog is running in the grass, not lying in ...</td>\n",
       "      <td>A dog running in the grass.&lt;/s&gt;The dog is lyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     A person on a horse jumps over a broken down a...   \n",
       "1     A person on a horse jumps over a broken down a...   \n",
       "2     A person on a horse jumps over a broken down a...   \n",
       "3                 Children smiling and waving at camera   \n",
       "4                 Children smiling and waving at camera   \n",
       "...                                                 ...   \n",
       "9995  A baby in a white and light purple outfit crying.   \n",
       "9996                    Baby in a purple onesie crying.   \n",
       "9997                    Baby in a purple onesie crying.   \n",
       "9998                    Baby in a purple onesie crying.   \n",
       "9999                        A dog running in the grass.   \n",
       "\n",
       "                                             hypothesis          label  \\\n",
       "0     A person is training his horse for a competition.        neutral   \n",
       "1         A person is at a diner, ordering an omelette.  contradiction   \n",
       "2                     A person is outdoors, on a horse.     entailment   \n",
       "3                     They are smiling at their parents        neutral   \n",
       "4                            There are children present     entailment   \n",
       "...                                                 ...            ...   \n",
       "9995             A baby is crying because it is hungry.        neutral   \n",
       "9996                   The baby is sleeping peacefully.  contradiction   \n",
       "9997                The child is under three years old.     entailment   \n",
       "9998                                The baby is a girl.        neutral   \n",
       "9999                   The dog is lying in the bedroom.  contradiction   \n",
       "\n",
       "          llm_label                                          rationale  \\\n",
       "0           neutral  The person could be training his horse for a c...   \n",
       "1     contradiction       The person on the horse is not at the diner.   \n",
       "2        entailment  The person is outdoors because the airplane is...   \n",
       "3           neutral  They are smiling at the camera, not their pare...   \n",
       "4        entailment  The children are present because they are smil...   \n",
       "...             ...                                                ...   \n",
       "9995        neutral  The baby is crying, but it is not necessarily ...   \n",
       "9996  contradiction                  The baby is crying, not sleeping.   \n",
       "9997     entailment                               The child is a baby.   \n",
       "9998        neutral               The baby is wearing a purple onesie.   \n",
       "9999  contradiction  The dog is running in the grass, not lying in ...   \n",
       "\n",
       "                                                  input  \n",
       "0     A person on a horse jumps over a broken down a...  \n",
       "1     A person on a horse jumps over a broken down a...  \n",
       "2     A person on a horse jumps over a broken down a...  \n",
       "3     Children smiling and waving at camera</s>They ...  \n",
       "4     Children smiling and waving at camera</s>There...  \n",
       "...                                                 ...  \n",
       "9995  A baby in a white and light purple outfit cryi...  \n",
       "9996  Baby in a purple onesie crying.</s>The baby is...  \n",
       "9997  Baby in a purple onesie crying.</s>The child i...  \n",
       "9998  Baby in a purple onesie crying.</s>The baby is...  \n",
       "9999  A dog running in the grass.</s>The dog is lyin...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read paper's answer\n",
    "paper = pd.read_csv('paper.csv', index_col=0)\n",
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper['premise'] = paper.input.str.split('\\n').apply(lambda x: x[0])\n",
    "paper.set_index(['premise', 'hypothesis'], inplace=True)\n",
    "# paper.index = paper.index.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['premise', 'hypothesis'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper['my_label'] = df['LLM_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(paper.label == paper.my_label) / len(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('historical - full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>prompt</th>\n",
       "      <th>rationale</th>\n",
       "      <th>split</th>\n",
       "      <th>correct_index</th>\n",
       "      <th>LLM_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, premise, hypothesis, prompt, rationale, split, correct_index, LLM_answer]\n",
       "Index: []"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "TYPE = 'historical'\n",
    "temp = pd.read_csv(f'{TYPE} - full.csv')\n",
    "\n",
    "import re\n",
    "temp.rationale = temp.rationale.astype(str)\n",
    "temp[~temp['rationale'].apply(lambda x: bool(re.match(r'\\d+\\.', x.strip())))]\n",
    "temp[temp.LLM_answer.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral          3550\n",
       "entailment       3325\n",
       "contradiction    3115\n",
       "Name: LLM_answer, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp.LLM_answer == 'entailed'] = 'entailment'\n",
    "temp[temp.LLM_answer == 'entails'] = 'entailment'\n",
    "temp[temp.LLM_answer == 'contradicts'] = 'contradiction'\n",
    "temp[temp.LLM_answer == 'contradict'] = 'contradiction'\n",
    "temp[temp.LLM_answer == 'contradicted'] = 'contradiction'\n",
    "temp[temp.LLM_answer == 'contradictory'] = 'contradiction'\n",
    "temp.LLM_answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(f'{TYPE} - full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
